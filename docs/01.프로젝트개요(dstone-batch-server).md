[Dstone Document Index](../../docs/Index.md)

# Dstone-Batch-Server 프로젝트 개요

---

## 1. 개요

`dstone-batch-server`는 Spring Cloud Data Flow와 Spring Cloud Skipper를 사용하여 데이터 처리 파이프라인과 배치(Batch) 애플리케이션을 구축, 배포, 관리하기 위한 서버 환경을 제공합니다.

이 프로젝트는 소스 코드를 직접 빌드하는 대신, 사전에 빌드된 서버 실행 파일을 포함하여, 대규모 데이터 처리 작업을 중앙에서 관리하고 모니터링하는 데 중점을 둡니다.

---

## 2. 주요 구성 요소

-   **Spring Cloud Data Flow Server (SCDF):**
    -   배치 및 스트림 애플리케이션의 파이프라인을 생성, 배포, 관리하는 핵심 서버입니다.
    -   웹 UI와 REST API를 제공하여 사용자가 쉽게 태스크(Task)를 정의하고 실행할 수 있도록 지원합니다.
    -   `modules/dataflow` 디렉토리에 실행 가능한 서버 파일이 위치합니다.

-   **Spring Cloud Skipper Server:**
    -   Spring Boot 애플리케이션의 생명주기(Lifecycle)를 관리하는 서버입니다.
    -   Dataflow와 함께 작동하여 배치 애플리케이션의 버전 관리, 업그레이드, 롤백 등의 기능을 수행합니다.
    -   `modules/skipper` 디렉토리에 실행 가능한 서버 파일이 위치합니다.

---

## 3. 디렉토리 구조

```text
dstone-batch-server/
├── bin/                    # 서버 실행 및 배포 스크립트
│   ├── 01.dataflow.bat     # Dataflow 서버 실행 스크립트 (Win)
│   ├── 01.dataflow.sh      # Dataflow 서버 실행 스크립트 (Linux/macOS)
│   ├── 02.skipper.bat      # Skipper 서버 실행 스크립트 (Win)
│   └── 02.skipper.sh       # Skipper 서버 실행 스크립트 (Linux/macOS)
├── conf/                   # 설정 파일
│   └── dataflow-server.yml # Dataflow 서버의 주요 설정 (DB, Skipper 연동 등)
├── docs/                   # 문서 및 이미지
│   └── resources/
│       └── images/
└── modules/                # 핵심 애플리케이션 모듈
    ├── dataflow/
    └── skipper/
```

---

## 4. 서버 실행 및 접속

1.  **환경 설정**: `conf/dataflow-server.yml` 파일에 데이터베이스 접속 정보, Skipper 서버 주소 등 운영에 필요한 설정을 구성합니다.

2.  **서버 실행**:
    -   `bin` 디렉토리의 스크립트를 사용하여 **Skipper 서버를 먼저 실행**한 후, **Dataflow 서버를 실행**합니다.
        ```bash
        # 1. Skipper 서버 실행
        ./bin/02.skipper.sh

        # 2. Dataflow 서버 실행
        ./bin/01.dataflow.sh
        ```

3.  **대시보드 접속**:
    -   웹 브라우저를 통해 Dataflow UI에 접속합니다. (기본 URL: `http://localhost:9393/dashboard`)

---

## 5. Batch 애플리케이션 연동 및 실행

### 5.1. Task 애플리케이션 등록

1.  **[Applications]** 메뉴에서 **[Add Application(s)]** 클릭
2.  아래 정보를 입력하여 `dstone-batch` 애플리케이션을 등록합니다.
    -   **Name**: `dstone-batch`
    -   **Type**: `Task`
    -   **Spring Boot Version**: `Spring Boot 2x`
    -   **URI**: `file:///workshop/dstone-batch/target/dstone-batch-0.0.1-SNAPSHOT.jar`
        > URI는 `dstone-batch` 프로젝트의 빌드된 JAR 파일이 위치한 절대 경로입니다.

    <img src="resources/images/dataflow-01-reg-app.png" alt="Dataflow App 등록" width="700" />

### 5.2. Task(Job) 정의 자동 생성

-   `dstone-batch` 애플리케이션은 `@AutoRegJob` 어노테이션이 붙은 잡(Job)들을 자동으로 Data Flow 서버에 Task로 등록하는 기능을 제공합니다.
-   Data Flow 서버가 실행 중인 상태에서 아래 URL을 호출하면 Task가 자동으로 생성됩니다.
    -   `http://localhost:6081/batch/regtasks`

    <img src="resources/images/dataflow-02-reg-tasks-by-app.png" alt="Dataflow Task 목록 등록" width="700" />

### 5.3. Task 실행

1.  **[Tasks]** 메뉴로 이동하여 실행할 Task(예: `samplejob`)의 오른쪽에 있는 `▶` (Launch) 아이콘을 클릭합니다.
    <img src="resources/images/dataflow-04-run-task-01.png" alt="Task 실행" width="700" />

2.  **Deployment Properties 설정**
    -   `javaOpts` 항목에 `-Dspring.profiles.active=dev`와 같이 실행 환경 프로필을 지정할 수 있습니다.
    <img src="resources/images/dataflow-04-run-task-03.png" alt="Deployment Property 설정" width="700" />

3.  **Arguments 설정**
    -   배치 잡에 전달할 파라미터(Job Parameters)를 `Arguments` 섹션에 추가합니다.
    <img src="resources/images/dataflow-04-run-task-04.png" alt="Arguments 설정" width="700" />

4.  **[LAUNCH THE TASK]** 버튼을 클릭하여 Task를 실행합니다.

### 5.4. 실행 로그 확인

-   **[Jobs]** 또는 **[Tasks]** 메뉴에서 실행된 잡/태스크를 선택한 후, **[VIEW LOG]** 버튼을 클릭하여 실행 로그를 확인할 수 있습니다.
    <img src="resources/images/dataflow-04-run-task-06.png" alt="로그 확인" width="700" />

---

## 6. 제약 사항

> ⚠️ **테이블명 대소문자 문제**
>
> -   Spring Cloud Data Flow(SCDF)는 메타데이터 저장을 위해 사용하는 테이블(`TASK_DEFINITIONS`, `STREAM_DEFINITIONS` 등)을 **소문자**로 생성하려고 시도합니다.
> -   만약 데이터베이스에 해당 테이블들이 이미 **대문자**로 생성되어 있다면, SCDF는 이를 인식하지 못하고 오류를 발생시킬 수 있습니다.
> -   현재 SCDF 버전에서는 테이블명을 강제로 대문자로 사용하도록 설정하는 공식적인 방법이 제한적이므로, 초기 환경 구성 시 데이터베이스 설정에 유의해야 합니다.